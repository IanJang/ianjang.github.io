<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - Category - Ian Jang&#39;s IT Blog</title>
        <link>https://ianjang.github.io/categories/python/</link>
        <description>Python - Category - Ian Jang&#39;s IT Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>ianjang0718@gmail.com (IanJang)</managingEditor>
            <webMaster>ianjang0718@gmail.com (IanJang)</webMaster><lastBuildDate>Thu, 09 Feb 2017 00:00:00 &#43;0900</lastBuildDate><atom:link href="https://ianjang.github.io/categories/python/" rel="self" type="application/rss+xml" /><item>
    <title>Python Flask with SQLAlchemy</title>
    <link>https://ianjang.github.io/python-flask-with-sqlalchemy/</link>
    <pubDate>Thu, 09 Feb 2017 00:00:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://ianjang.github.io/python-flask-with-sqlalchemy/</guid>
    <description><![CDATA[들어가며 pymysql을 이용해서 flask에서 Database를 다뤄보았습니다. 뭔가 부족한 감이 있었습니다. 자원을 체계적으로 관리하기 힘들어 보였습니다. 그래서 대안을 찾아보았고 SQLAlchemy과 Flask-SQLAlchemy에 대한 사례들이 있었습니다. 본문에 관련 내용을 정리해 보았습니다.
 SQLAlchemy vs. Flask-SQLAlchemy 우선 모듈이 지속적으로 관리가 되고 있는지가 궁금했습니다. Github에서 각각의 저장소를 살펴봤습니다. 먼저 Flask-SQLAlchemy는 2.1 버전이 최신 stable 버전이며, 2015년 10월 23일에 Release 되었습니다. 반면 SQLAlchemy는 22일 전인 2017년 1월 18일에 1.1.5 버전이 release 되었으며, Release history를 보면 꾸준히 버전이 Update 되고 있음을 확인할 수 있었습니다.]]></description>
</item><item>
    <title>Python BeautifulSoup 이용 크롤링하기</title>
    <link>https://ianjang.github.io/python-beautifulsoup-%EC%9D%B4%EC%9A%A9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0/</link>
    <pubDate>Sat, 04 Feb 2017 00:00:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://ianjang.github.io/python-beautifulsoup-%EC%9D%B4%EC%9A%A9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0/</guid>
    <description><![CDATA[들어가며 Python을 이용하여 크롤링을 해보았습니다. BeautifulSoup를 이용한 사례들이 많았고 참고하여 진행해 보았습니다.
 BeautifulSoup 설치 1  $ pip install beautifulSoup4    크롤링 시작하기 클리앙의 모두의공원 카테고리의 글을 크롤링해보려 합니다. 레퍼런스 사이트내용을 참고해서 아래와 같이 진행해 보았습니다. 우선 해당 페이지의 모든 html text를 긁어와봅시다.
1 2 3 4 5 6 7 8  import requests from bs4 import BeautifulSoup if __name__ == &#39;__main__&#39;: url = &#34;http://www.clien.net/cs2/bbs/board.php?bo_table=park&#34; source_code = requests.]]></description>
</item></channel>
</rss>
