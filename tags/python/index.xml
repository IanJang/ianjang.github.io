<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - Tag - Ian Jang&#39;s IT Blog</title>
        <link>https://ianjang.github.io/tags/python/</link>
        <description>Python - Tag - Ian Jang&#39;s IT Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>ianjang0718@gmail.com (IanJang)</managingEditor>
            <webMaster>ianjang0718@gmail.com (IanJang)</webMaster><lastBuildDate>Thu, 09 Feb 2017 00:00:00 &#43;0900</lastBuildDate><atom:link href="https://ianjang.github.io/tags/python/" rel="self" type="application/rss+xml" /><item>
    <title>Python Flask with SQLAlchemy</title>
    <link>https://ianjang.github.io/python-flask-with-sqlalchemy/</link>
    <pubDate>Thu, 09 Feb 2017 00:00:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://ianjang.github.io/python-flask-with-sqlalchemy/</guid>
    <description><![CDATA[들어가며 pymysql을 이용해서 flask에서 Database를 다뤄봤다. 헌데 뭔가 부족한 감이있다. 자원을 체계적으로 관리하기 힘들어 보였다. 그래서 다른 모듈이 있지 않을까 하여 구글링해보았다. 그 결과 SQLAlchemy 또는 Flask-SQLAlchemy를 이용한 케이스들이 많더라. 어떤것을 사용하는게 좋을까?
SQLAlchemy vs. Flask-SQLAlchemy 우선 지속적으로 관리가 되고 있는지가 궁금했다. Github에서 각각의 repository를 살펴봤다. 먼저 Flask-SQLAlchemy는 2.1 버전이 stable한 버전이며 2015년 10월 23일에 Release 되었다. 반면 SQLAlchemy는 22일 전인 2017년 1월 18일에 1.1.5 버전이 release 되었으며, Release history를 보면 꾸준히 버전이 Update 되고 있음을 확인할 수 있었다.]]></description>
</item><item>
    <title>Python BeautifulSoup 이용 크롤링하기</title>
    <link>https://ianjang.github.io/python-beautifulsoup-%EC%9D%B4%EC%9A%A9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0/</link>
    <pubDate>Sat, 04 Feb 2017 00:00:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://ianjang.github.io/python-beautifulsoup-%EC%9D%B4%EC%9A%A9-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EA%B8%B0/</guid>
    <description><![CDATA[BeautifulSoup 설치 Python을 통한 클로링에 대해서 서치해보니, beautifulSoup를 활용한 예제들이 많더라. 우선 설치해보자.
1  $ pip install beautifulSoup4   크롤링 시작하기 클리앙의 모두의공원 카테고리의 글을 크롤링해보려 한다. 레퍼런스 사이트내용을 참고해서 아래와 같이 진행해 보았다. 우선 해당 페이지의 모든 html text를 긁어와보자
1 2 3 4 5 6 7 8  import requests from bs4 import BeautifulSoup if __name__ == &#39;__main__&#39;: url = &#34;http://www.clien.net/cs2/bbs/board.php?bo_table=park&#34; source_code = requests.get(url) plain_text = source_code.]]></description>
</item></channel>
</rss>
